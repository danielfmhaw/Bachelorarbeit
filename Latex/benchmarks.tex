%! Author = danielmendes
%! Date = 21.10.24
\chapter{Überblick}

\section{Einführung in Benchmarks}

Benchmarks dienen dazu, praktisch und effektiv zu untersuchen, wie sich ein
System unter Last verhält. Die wichtigste Erkenntnis, die man aus Benchmarks
gewinnen kann, sind die Probleme und Fehler, die man systematisch dokumentieren
und nach Priorität abarbeiten sollte. Das Ziel von Benchmarks ist die Reduzierung
und Bewertung von unerwünschtem Verhalten sowie die Analyse, wie sich das
System derzeit und unter simulierten, zukünftigen, anspruchsvolleren Bedingungen
verhalten könnte.

Es gibt zwei verschiedene Techniken für Benchmarks. Die erste zielt darauf ab,
die Applikation als Ganzes zu testen (full-stack). Dabei wird nicht nur die
Datenbank getestet, sondern die gesamte Applikation, einschließlich des Webservers,
des Netzwerks und des Applikationscodes. Der Ansatz dahinter ist, dass ein Nutzer
genauso lange auf eine Abfrage warten muss, wie das gesamte System benötigt.
Daher sollte diese Wartezeit so gering wie möglich sein. Es kann dabei vorkommen,
dass MySQL nicht immer das Bottleneck ist.\footnote{Gemeint ist ein Engpass beim Transport von Daten oder Waren, der maßgeblichen Einfluss auf die Abarbeitungsgeschwindigkeit hat. Optimierungsversuche an anderer Stelle führen oft nur zu geringen oder gar keinen messbaren Verbesserungen der Gesamtsituation. (\cite{bottleneck})}

Full-Stack-Benchmarks haben jedoch auch Nachteile. Sie sind schwieriger zu erstellen
und insbesondere schwieriger korrekt einzurichten. Wenn man lediglich verschiedene
Schemas und Abfragen in MySQL auf ihre Performance testen möchte, gibt es sogenannte
Single-Component-Benchmarks. Diese analysieren ein spezifisches Problem in der
Applikation und sind deutlich einfacher zu erstellen. Ein weiterer Vorteil besteht
darin, dass nur ein Teil des gesamten Systems getestet wird, wodurch die Antwortzeiten
kürzer sind und man schneller Ergebnisse erhält.

Wenn bei Benchmarks schlechte Designentscheidungen getroffen werden, kann dies zu einer
falschen Interpretation des Systems führen, da die Ergebnisse nicht die Realität widerspiegeln.
Die Größe des Datensatzes und des Workloads muss realistisch sein. Idealerweise verwendet
man einen Snapshot\footnote{Snapshots bestehen größtenteils aus Metadaten, die den Zustand Ihrer Daten definieren, und sind keine vollständige Duplikation der Daten auf Ihrer Festplatte. Snapshots werden häufig für Test-/Entwicklungsaufgaben verwendet. (\cite{snapshot}) } des tatsächlichen produktiven Datensatzes.
Gibt es keine Produktionsdaten, sollten die Daten und der Workload simuliert werden,
da realistische Benchmarks komplex und zeitaufwendig sein können.

Häufige Fehler beim Durchführen von Benchmarks sind unter anderem, dass nur ein kleiner Teil
der tatsächlichen Datensatzgröße verwendet wird und die Datensätze unkorrekt gleichmäßig
verteilt sind. In der Realität können Hotspots auftreten. Bei zufällig generierten Werten
kommt es hingegen häufig zu unrealistisch gleichmäßig verteilten Datensätzen. Ein weiterer
Fehler besteht darin, dass man beim Testen einer Anwendung nicht das tatsächliche
Benutzerverhalten nachstellt. Wenn gleiche Abfragen in einer Schleife ausgeführt werden,
muss man außerdem auf das Caching achten, da sonst falsche Annahmen über die Performance
getroffen werden können. Zudem wird oft die Warmmachphase des Systems vollständig ignoriert.
Kurze Benchmarks können schnell zu falschen Annahmen über die Performance des Systems führen.

Um verlässliche Ergebnisse zu erhalten, sollte ein Benchmark ausreichend lange laufen,
um den stabilen Zustand des Systems zu beobachten, insbesondere bei Servern mit großen
Datenmengen und viel Speicher. Dabei ist es wichtig, so viele Informationen wie möglich zu
erfassen und sicherzustellen, dass der Benchmark wiederholbar ist, da unzureichende oder
fehlerhafte Tests wertlos sind. Außerdem ist es wichtig, die Ergebnisse in einem Diagramm
darzustellen, da auftretende Phänomene sonst anhand einer tabellarischen Darstellung nicht
erkannt werden können.

\section{Measures}
\begin{itemize}[label={--}]
    \item \textbf{Durchsatz (Throughput):} Der Durchsatz ist die Anzahl an Transaktionen pro Zeiteinheit.
    Er ist standardisiert, und Datenbankanbieter versuchen, diesen zu optimieren.
    Meistens werden Transaktionen pro Sekunde (oder manchmal pro Minute) als Einheit verwendet.
    \item \textbf{Antwortzeiten (Latenz):} Die Antwortzeit misst die gesamte Zeit, die für eine Abfrage benötigt wird.
    Diese kann, abhängig von der Applikation, in Mikrosekunden (µs), Millisekunden (ms), Sekunden oder Minuten angegeben werden.
    Von dieser Zeit können aggregierte Antwortzeiten wie Durchschnitt, Maximum, Minimum und Perzentile abgeleitet werden.
    Das Maximum ist oft eine weniger sinnvolle Metrik, da es sich nicht gut wiederholen lässt.
    Daher nutzt man eher Perzentile bei den Antwortzeiten.
    Wenn beispielsweise das 95. Perzentil der Antwortzeit bei 5 ms liegt, bedeutet dies, dass mit einer Wahrscheinlichkeit von 95 \% die Abfrage in weniger als 5 ms abgeschlossen ist.
    \item \textbf{Nebenläufigkeit (Concurrency):} Die Nebenläufigkeit auf dem Webserver lässt sich nicht zwangsläufig auf den Datenbankserver übertragen.
    Eine genauere Messung der Gleichzeitigkeit auf dem Webserver besteht darin, zu bestimmen, wie viele gleichzeitige Anfragen zu einem bestimmten Zeitpunkt ausgeführt werden.
    Es kann auch geprüft werden, ob der Durchsatz sinkt oder die Antwortzeiten steigen, wenn die Gleichzeitigkeit zunimmt.
    Beispielsweise benötigt eine Website mit „50.000 Benutzern gleichzeitig“ vielleicht nur 10 oder 15 gleichzeitig laufende Abfragen.
    \item \textbf{Skalierbarkeit (Scalability):} Skalierbarkeit ist wichtig für Systeme, die ihre Performance unter unterschiedlich starken Workloads beibehalten müssen.
    Ein ideales System würde doppelt so viele Abfragen beantworten (Throughput), wenn doppelt so viele „Arbeiter“ versuchen, die Aufgaben zu erfüllen.
    Die meisten Systeme sind jedoch nicht linear skalierbar und zeigen Leistungseinbußen, wenn die Parameter variieren.
\end{itemize}

\section{Tools}\label{sec:tools}
\subsection{Einführung}\label{subsec:einfuhrung}

\begin{itemize}
    \item \cite{sysbench_mysql}
    \item \cite{sysbench_repo}
\end{itemize}

Als Haupttool, um Benchmarktests durchzuführen, habe ich mich für Sysbench entschieden. Sysbench ist ein Open-Source-Tool, das ein skriptfähiges, multi-threaded Benchmark-Tool, das auf LuaJIT basiert. Es wird auch hauptsächlich für Datenbankbenchmarks verwendet, kann jedoch auch dazu eingesetzt werden, beliebig komplexe Arbeitslasten zu erstellen, die keinen Datenbankserver erfordern. Dabei werden Tests auf verschiedenen Systemressourcen, wie CPU, Speicher, I/O und Datenbanken wie MySQL verwendet.

Im Zuge der Recherchearbeit habe ich mir auch andere Benchmarking-Tools betrachtet, wie z.B. Benchbase \cite{DifallahPCC13} oder mybench \cite{mybench_repo}. Die größten Vorteile von Sysbench habe ich in der Skriptfähigkeit und Flexibilität gesehen. D.h. dass ich benutzerdefinierte Benchmarks schneller und unkompliziert erstellen kann. Außerdem hat sich Sysbench als de facto Standard im Bereich der Datenbankbenchmarks etabliert \cite{mybench_comparison}. Dadurch stehen eine breite Nutzerbasis und viele verfügbare Ressourcen zur Verfügung. Im Vergleich zu den anderen Tools bietet allerdings Sysbench eine weniger präzise Steuerung der Ergebnisrate und der Transaktionen. Außerdem haben Tools wie mybench die Möglichkeit, in Echtzeit umfassende Visualisierungen darzustellen. Damit können Metriken live in einem Diagramm angezeigt werden \cite{mybench_user_interface}. Dieses Feature ist sicherlich hilfreich, aber in meinem Fall habe ich abgewogen und bin zu dem Entschluss gekommen, dass die einfachere Bedienung für mich der ausschlaggebende Grund, neben dem Fakt, dass Sysbench der de facto Standard ist.

Da die Graphen aber trotzdem eine entscheidende Rolle bei der Analyse darstellen, werde ich das Tool Gnuplot \cite{gnuplot} dafür benutzen, um die Werte nach der Durchführung des Benchmarks zu visualisieren.

\subsection{Kurze Einführung in die Tools}\label{sec:kurze-einfuhrung-in-die-tools}

Zunächst müssen die beiden Tools installiert werden.
Auf einem Mac erfolgt dies über:

\begin{lstlisting}[label={lst:install tools}]
brew install sysbench
brew install gnuplot
\end{lstlisting}

Mit der Hilfe von Homebrew.
Des Weiteren muss der MySQL-Server korrekt gestartet sein und eine Datenbank erstellt werden mit:

\begin{lstlisting}[label={lst:create databse}]
CREATE DATABASE sbtest;
\end{lstlisting}

Um einfach Testdaten in die Datenbank einzufügen, kann dieser Befehl verwendet werden:

\begin{lstlisting}[style=custom_daniel,label={lst:sysbenchrun}]
sysbench --db-driver=mysql --mysql-host=localhost --mysql-user=YOUR_USER --mysql-password=YOUR_PASSWORD --mysql-db=sbtest oltp_insert --tables=10 --table-size=100000 prepare
\end{lstlisting}

\texttt{YOUR\_USER} und \texttt{YOUR\_PASSWORD} müssen entsprechend ersetzt werden.

\lstinputlisting[
    language=bash,
    caption=Sysbench Script,
    label={lst:sysbench_monitor},
    style=custom_daniel,
]{Scripts/sysbench_monitor.sh}

\lstinputlisting[
    language=gnuplot,
    caption=Gnuplot Script,
    label={lst:plot_sysbench},
    style=custom_daniel,
]{Scripts/plot_sysbench.gp}